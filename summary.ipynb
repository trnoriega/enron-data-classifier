{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Enron Data\n",
    "## Based on Udacity intro to machine learning course\n",
    "\n",
    "### Data sources:\n",
    "- Raw email text data can be found at: https://www.cs.cmu.edu/~./enron/enron_mail_20150507.tgz\n",
    "and a breakdown of emails by sender can be found [here](data/emails_by_address/)\n",
    "- The financial data was compiled from [this file](data/financial_data.pdf)\n",
    "- The persons of interest \"pois\" come from [this file](data/poi_names.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Support functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tools.feature_format import featureFormat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data already preprocessed in [outlier_removal](outlier_removal.ipynb) and [imputing_data](imputing_data.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('imputer_dicts.pkl', 'rb') as f:\n",
    "    imputer_dicts = pickle.load(f)\n",
    "\n",
    "mean_data_dict = imputer_dicts['mean']\n",
    "\n",
    "# Start with all features except: 'email_address'\n",
    "all_feature_names = ['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments',\\\n",
    "'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi',\\\n",
    "'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances',\\\n",
    "'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income',\\\n",
    "'long_term_incentive', 'from_poi_to_this_person']\n",
    "\n",
    "mean_data = featureFormat(mean_data_dict, all_feature_names)\n",
    "labels, features = mean_data[:,0], mean_data[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "pipe = Pipeline([\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('polynomials', PolynomialFeatures(2)),\n",
    "                 ('feature_selr', SelectFromModel(\n",
    "                                                 ExtraTreesClassifier(\n",
    "                                                     random_state=2,\n",
    "                                                     class_weight='balanced'), \n",
    "                                                 threshold='mean')),\n",
    "                ('estimator', GaussianNB())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes :\n",
      "\n",
      "- recall [ 0.5  0.6  0.2]\n",
      "Mean: 0.43 (+/-0.17)\n",
      "- precision [ 0.42857143  0.375       0.33333333]\n",
      "Mean: 0.38 (+/-0.04)\n",
      "- f1 [ 0.46153846  0.46153846  0.25      ]\n",
      "Mean: 0.39 (+/-0.10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def score_display(clf, features, labels, title):\n",
    "    print title, ':\\n'\n",
    "    for scoring in ['recall', 'precision', 'f1']:\n",
    "        cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=24)\n",
    "        scores = cross_val_score(pipe, features, labels, cv=cv, scoring=scoring)\n",
    "        mean, std = np.mean(scores), np.std(scores)\n",
    "        print '-', scoring, scores\n",
    "        print 'Mean: %0.2f (+/-%0.2f)' % (mean, std)\n",
    "\n",
    "score_display(pipe, features, labels, 'Naive-Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 5 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of  75 | elapsed:    5.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)}\n",
      "0.19621749409\n"
     ]
    }
   ],
   "source": [
    "### Try a variety of classifiers\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "params = {'estimator': [SVC(), \n",
    "                        AdaBoostClassifier(),\n",
    "                        ExtraTreesClassifier(),\n",
    "                        RandomForestClassifier(),\n",
    "                        LogisticRegression()]\n",
    "         }\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=params,\n",
    "                    cv=15, verbose=1,\n",
    "                    n_jobs=-1, scoring='f1')\n",
    "\n",
    "grid.fit(features, labels)\n",
    "print grid.best_params_\n",
    "print grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>\n",
      "0.2 0.361068373539\n",
      "<class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n",
      "0.177777777778 0.362433476229\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "0.144444444444 0.303477784083\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "0.1 0.270801280155\n",
      "<class 'sklearn.svm.classes.SVC'>\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "def find_top_scores(grid, cutoff=5, cv=5):\n",
    "\n",
    "    grid_results = grid.cv_results_\n",
    "\n",
    "    score_keys = []\n",
    "    end_str = '_test_score'\n",
    "    start_str = 'split'\n",
    "    for num in range(cv):\n",
    "        complete_str = start_str+str(num)+end_str\n",
    "        score_keys.append(complete_str)\n",
    "\n",
    "    ranks = grid_results['rank_test_score']\n",
    "    for rank in range(1,cutoff+1):\n",
    "        i = np.where(ranks == rank)[0][0]\n",
    "        print type(grid_results['params'][i]['estimator'])\n",
    "        best_test_scores = []\n",
    "        for key in score_keys:\n",
    "            best_test_scores.append(grid_results[key][i])\n",
    "        print np.mean(best_test_scores), np.std(best_test_scores)\n",
    "    return best_test_scores\n",
    "\n",
    "best = find_top_scores(grid, 5, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DTC = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "ABC = AdaBoostClassifier(base_estimator=DTC, random_state=42)\n",
    "ABC_params = {'polynomials__degree': [2,3],\n",
    "              'estimator': [ABC],\n",
    "              'estimator__base_estimator__max_depth': [None, 3, 6, 12, 24, 48],\n",
    "              'estimator__base_estimator__min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "              'estimator__n_estimators': [25, 50, 100, 250],\n",
    "              'estimator__learning_rate': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "ETC = ExtraTreesClassifier(class_weight='balanced', random_state=42)\n",
    "ETC_params = {'polynomials__degree': [2,3],\n",
    "              'estimator': [ETC],\n",
    "              'estimator__max_depth': [None, 3, 6, 12, 24, 48],\n",
    "              'estimator__min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "              'estimator__n_estimators': [25, 50, 100],\n",
    "              'estimator__max_features': [1, 2, 4, 6, 8, 10]}\n",
    "\n",
    "RF = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "RF_params = {'polynomials__degree': [2,3],\n",
    "             'estimator': [RF],\n",
    "             'estimator__max_depth': [None, 3, 6, 12, 24, 48],\n",
    "             'estimator__min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "             'estimator__n_estimators': [25, 50, 100],\n",
    "             'estimator__max_features': [1, 2, 4, 6, 8, 10]}\n",
    "\n",
    "LR = LogisticRegression(solver='lbfgs')\n",
    "LR_params = {'polynomials__degree': [2,3],\n",
    "             'estimator': [LR],\n",
    "             'estimator__C': [1e-2, 1e-1, 1, 1e1, 1e2],\n",
    "             'estimator__class_weight': [None, 'balanced'],\n",
    "             'estimator__max_iter': [100, 200],\n",
    "             'estimator__tol': [1e-4, 5e-4, 1e-3],\n",
    "             'estimator__warm_start': [False, True]}\n",
    "\n",
    "large_grid_params = [ABC_params, ETC_params, RF_params, LR_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3360 candidates, totalling 16800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 326 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 926 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1376 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1926 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3326 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4176 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5126 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6176 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7326 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done 8576 tasks      | elapsed: 30.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9926 tasks      | elapsed: 34.7min\n",
      "[Parallel(n_jobs=-1)]: Done 11376 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12926 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=-1)]: Done 14576 tasks      | elapsed: 49.7min\n",
      "[Parallel(n_jobs=-1)]: Done 16326 tasks      | elapsed: 53.8min\n",
      "[Parallel(n_jobs=-1)]: Done 16800 out of 16800 | elapsed: 174.6min finished\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    large_grid = GridSearchCV(pipe,\n",
    "                              param_grid=large_grid_params,\n",
    "                              cv=5, \n",
    "                              verbose=1,\n",
    "                              n_jobs=-1,\n",
    "                              scoring='f1')\n",
    "\n",
    "    large_grid.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('large_grid.pkl', 'wb') as f:\n",
    "    pickle.dump(large_grid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Dump classifier, dataset, and features_list so anyone can check your results.\n",
    "\n",
    "from tools.tester import dump_classifier_and_data\n",
    "my_dataset = fin_data\n",
    "features_list = selected_feature_names\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
