{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Enron Data\n",
    "## Based on Udacity intro to machine learning course\n",
    "\n",
    "### Goal\n",
    "\n",
    "The goal of this analysis is to use publicly available data from the investigation into the [2001 Enron scandal](https://en.wikipedia.org/wiki/Enron_scandal) to develop a machine learning algorithm that could identify persons of interest (referred to as \"pois\") with precision and recall  >0.3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sources:\n",
    "- Raw email text data can be found at: https://www.cs.cmu.edu/~./enron/enron_mail_20150507.tgz\n",
    "and a breakdown of emails by sender (provided by the course instructors) can be found [here](data/emails_by_address/)\n",
    "- The financial data was organized by the course instructors and organized in [this dictionary](data/final_project_dataset.pkl) and was compiled from [this file](data/financial_data.pdf)\n",
    "- The pois were manually compiled by the course instructions and come from [this file](data/poi_names.txt)\n",
    "\n",
    "- The intermediate data files for the analysis steps described below can be found [here](https://www.dropbox.com/sh/iyd7j82lsghxtgr/AADFlMHuNZdeq5dHCJ7ykIppa?dl=0)\n",
    "- The final dataset, feature names, and estimator can be found [here](https://www.dropbox.com/sh/bk6amqwcx133rhp/AACOLu6NQRIAhwz6H4JgO3nPa?dl=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature generation \n",
    "\n",
    "I generated two sets of features from the data:\n",
    "\n",
    "1) Polynomial features derived from the financial data: The generation, scaling, and testing of these features can be seen in the [polynomial_features](polynomial_features.ipynb) notebook\n",
    "\n",
    "2) Word features derived from raw emails sent by Enron employees: \n",
    "- The extraction and cleaning up of the text data can be seen in the [email_features](email_features.ipynb) notebook\n",
    "- The vectorization of the email words based on term frequency inverse document frequency analysis can be seen in the [vectorize_email_features](vectorize_email_features.ipynb) notebook\n",
    "- Finally, the conversion of the generated features into a usable dictionary can be seen in the [save_email_features](save_email_features.ipynb) notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter optimization\n",
    "\n",
    "Once a set of features had been generated I tested 5 different machine learning classification algorithms to see which could identify pois most effectively:\n",
    "\n",
    "1) Gaussian Naive Bayes\n",
    "\n",
    "2) Support Vector Machines\n",
    "\n",
    "3) AdaBoost\n",
    "\n",
    "4) Random Forests\n",
    "\n",
    "5) Logistic Regression\n",
    "\n",
    "Of these five AdaBoost consistently provided the best results. \n",
    "\n",
    "The process of identifying the best classification algorithm and tuning its hyper parameters to maximize performance can be seen in the [parameter_optimization](parameter_optimization.ipynb) notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the final dataset, feature names, and estimator can be found [here](https://www.dropbox.com/sh/bk6amqwcx133rhp/AACOLu6NQRIAhwz6H4JgO3nPa?dl=0)\n",
    "\n",
    "The performance of the final analysis can be seen here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Done loading\n",
      "Start testing\n",
      "Testing splits: \n",
      ". 5.0 % . 10.0 % . 15.0 % . 20.0 % . 25.0 % . 30.0 % . 35.0 % . 40.0 % . 45.0 % . 50.0 % . 60.0 % . 65.0 % . 70.0 % . 75.0 % . 80.0 % . 85.0 % . 90.0 % . 95.0 % . 100.0 % \n",
      "ESTIMATOR:\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=42, splitter='best'),\n",
      "          learning_rate=0.01, n_estimators=25, random_state=42)\n",
      "RESULTS:\n",
      "Total predictions: 15000\n",
      "True positives:  722\n",
      "False positives: 1013\n",
      "False negatives: 1278\n",
      "True negatives: 11987\n",
      "PERFORMANCE:\n",
      "Accuracy: 0.84727\n",
      "Precision: 0.41614\n",
      "Recall: 0.36100\n",
      "F1: 0.38661\n",
      "Done testing\n"
     ]
    }
   ],
   "source": [
    "run tools/tester.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
