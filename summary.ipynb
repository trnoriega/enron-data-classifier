{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Enron Data\n",
    "## Based on Udacity intro to machine learning course\n",
    "\n",
    "### Data sources:\n",
    "- Raw email text data can be found at: https://www.cs.cmu.edu/~./enron/enron_mail_20150507.tgz\n",
    "and a breakdown of emails by sender can be found [here](data/emails_by_address/)\n",
    "- The financial data was compiled from [this file](data/financial_data.pdf)\n",
    "- The persons of interest \"pois\" come from [this file](data/poi_names.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Support functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# For make_features_labels\n",
    "from tools.feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "# For IsolationForestTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def make_features_labels(dataset, feature_names, remove_nan=False):\n",
    "    \"\"\"\n",
    "    Quick way to split a dataset into features and labels based on feature names\n",
    "    \"\"\"\n",
    "    data = featureFormat(dataset, feature_names, \n",
    "                         sort_keys=True, remove_NaN=remove_nan, remove_all_zeroes=False)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    labels = np.array(labels)\n",
    "    features = np.array(features)\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "class IsolationForestTransformer(IsolationForest):\n",
    "    \"\"\"\n",
    "    Makes IsolationForest classifier into a transformer that returns an array with\n",
    "    potential outliers removed\n",
    "    \n",
    "    Inputs:\n",
    "    X: Array with (n_samples, n_features)\n",
    "    \n",
    "    arguments:\n",
    "    num_to_remove[=False]: an int of how many potential sample outliers should be \n",
    "    removed from X\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_to_remove=None, **kwargs):\n",
    "        self.num_to_remove = num_to_remove\n",
    "        super(IsolationForestTransformer, self).__init__(**kwargs)\n",
    "          \n",
    "    def get_num_to_remove(self):\n",
    "        return self.num_to_remove\n",
    "    \n",
    "    def transform(self, X, y):\n",
    "        scores = self.decision_function(X)\n",
    "        \n",
    "        try:\n",
    "            start = self.get_num_to_remove()\n",
    "        except AttributeError:\n",
    "            print 'num_to_remove was not provided'\n",
    "        \n",
    "        idxs = np.argsort(scores)\n",
    "        \n",
    "        # returns X minus the features with the lowest anomaly scores\n",
    "        return X[idxs[start:],:], y[idxs[start:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary containing financial data and some email features (to_ from_poi)\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open('data/final_project_dataset.pkl', 'rb') as f:\n",
    "    fin_data = pickle.load(f)\n",
    "\n",
    "# Remove 'TOTAL' from data\n",
    "del fin_data['TOTAL']\n",
    "\n",
    "# Start with all features except: 'email_address'\n",
    "all_feature_names = ['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments',\\\n",
    "'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi',\\\n",
    "'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances',\\\n",
    "'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income',\\\n",
    "'long_term_incentive', 'from_poi_to_this_person']\n",
    "\n",
    "all_features, all_labels = make_features_labels(fin_data, all_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 20,  0,  0,\n",
       "        0, 12])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(all_features == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Imputer, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "pipe1 = Pipeline([\n",
    "                ('imputer', Imputer(strategy='mean',\n",
    "                                    verbose=1)),\n",
    "                ('scaler', StandardScaler())\n",
    "                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 19) (141,)\n"
     ]
    }
   ],
   "source": [
    "X_imped_scaled = pipe.fit_transform(all_features, all_labels)\n",
    "IFT = IsolationForestTransformer(num_to_remove=4, random_state=0)\n",
    "IFT.fit(X_imped_scaled)\n",
    "X_outlied, y_outlied = IFT.transform(X_imped_scaled, all_labels)\n",
    "print X_outlied.shape, y_outlied.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([\n",
    "                ('polynomials_addr', PolynomialFeatures(2)),\n",
    "                ('feature_selr', SelectFromModel(\n",
    "                                                 ExtraTreesClassifier(\n",
    "                                                     random_state=2,\n",
    "                                                     class_weight='balanced'), \n",
    "                                                 threshold='mean'))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 210)\n",
      "(141, 66)\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "X_poly = poly.fit_transform(X_outlied)\n",
    "print X_poly.shape\n",
    "\n",
    "X_ready = pipe2.fit_transform(X_outlied, y_outlied)\n",
    "print X_ready.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 16 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=100.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-f1 score: 0.04 (+/- 0.33)\n",
      "-precision score: 0.10 (+/- 0.27)\n",
      "-recall score: 0.22 (+/- 0.59)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "def fit_print_scores(clf, features, labels):\n",
    "    \n",
    "    f1_scores = cross_val_score(clf, features, labels, cv=100, scoring='f1')\n",
    "    print '-f1 score: %0.2f (+/- %0.2f)' % (f1_scores.mean(), \n",
    "                                           f1_scores.std() * 2)\n",
    "    precision_scores = cross_val_score(clf, features, labels, cv=5, scoring='precision')\n",
    "    print '-precision score: %0.2f (+/- %0.2f)' % (precision_scores.mean(), \n",
    "                                                  precision_scores.std() * 2)\n",
    "    recall_scores = cross_val_score(clf, features, labels, cv=5, scoring='recall')\n",
    "    print '-recall score: %0.2f (+/- %0.2f)' % (recall_scores.mean(), \n",
    "                                                  recall_scores.std() * 2)\n",
    "\n",
    "print 'All features:'\n",
    "fit_print_scores(GaussianNB(), X_ready, y_outlied)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new features from the email text\n",
    "\n",
    "word_dict_subset is a dictionary that contains emails from all of the people\n",
    "with financial data AND email data available separated into 'to' and 'from' categories. \n",
    "It was made like this:\n",
    "```python\n",
    "from tools.email_analysis import find_email_paths, word_dict_maker\n",
    "data_emails = [item['email_address'] for key, item in fin_data.items()]\n",
    "emailpath_tuples = find_emailpaths()\n",
    "fin_emailpath_tuples = [tup for tup in emailpath_tuples if tup[1] in data_emails]\n",
    "word_dict_subset = word_dict_maker(fin_emailpath_tuples)\n",
    "```\n",
    "word-dict_subset has 86 people total, 14 pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/word_dict_subset.pkl', 'rb') as f:\n",
    "    data_text = pickle.load(f)\n",
    "\n",
    "#Separate data into emails from, to, or all-together\n",
    "from tools.email_analysis import email_list_and_labels\n",
    "to_emails, to_email_labels = email_list_and_labels(data_text, 'to')\n",
    "from_emails, from_email_labels = email_list_and_labels(data_text, 'from')\n",
    "all_emails, all_email_labels = email_list_and_labels(data_text, 'all')\n",
    "\n",
    "# Create a tf-idf vectors of each person's to, from, and all-together emails\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.5)\n",
    "\n",
    "to_feature_matrix = vectorizer.fit_transform(to_emails)\n",
    "from_feature_matrix = vectorizer.fit_transform(from_emails)\n",
    "all_feature_matrix = vectorizer.fit_transform(all_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "print 'To emails scores:'\n",
    "fit_print_scores(clf, to_feature_matrix.toarray(), to_email_labels)\n",
    "print '\\nFrom emails scores:'\n",
    "fit_print_scores(clf, from_feature_matrix.toarray(), from_email_labels)\n",
    "print '\\nAll emails scores:'\n",
    "fit_print_scores(clf, all_feature_matrix.toarray(), all_email_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like email word extraction does not yield very promising results, will drop for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian naive Bayes:\n",
      "-f1 score: 0.04 (+/- 0.33)\n",
      "-precision score: 0.10 (+/- 0.27)\n",
      "-recall score: 0.22 (+/- 0.59)\n",
      "\n",
      "Support vector machine:\n",
      "-f1 score: 0.00 (+/- 0.00)\n",
      "-precision score: 0.00 (+/- 0.00)\n",
      "-recall score: 0.00 (+/- 0.00)\n",
      "\n",
      "Random forest:\n",
      "-f1 score: 0.01 (+/- 0.13)\n",
      "-precision score: 0.30 (+/- 0.80)\n",
      "-recall score: 0.17 (+/- 0.42)\n",
      "\n",
      "Extra trees:\n",
      "-f1 score: 0.04 (+/- 0.36)\n",
      "-precision score: 0.63 (+/- 0.74)\n",
      "-recall score: 0.22 (+/- 0.59)\n",
      "\n",
      "AdaBoost:\n",
      "-f1 score: 0.02 (+/- 0.24)\n",
      "-precision score: 0.24 (+/- 0.41)\n",
      "-recall score: 0.28 (+/- 0.55)\n",
      "\n",
      "Logistic regression:\n",
      "-f1 score: 0.01 (+/- 0.14)\n",
      "-precision score: 0.24 (+/- 0.78)\n",
      "-recall score: 0.22 (+/- 0.59)\n"
     ]
    }
   ],
   "source": [
    "### Try a variety of classifiers\n",
    "# for ease rename balanced_selected_features and balanced_selected_labels\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "features = X_ready\n",
    "labels = y_outlied\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "print 'Gaussian naive Bayes:'\n",
    "fit_print_scores(clf, features, labels)\n",
    "\n",
    "#Use scaled features for SVC\n",
    "from sklearn.svm import SVC \n",
    "clf = SVC()\n",
    "print '\\nSupport vector machine:'\n",
    "fit_print_scores(clf, features, labels)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "clf = RandomForestClassifier()\n",
    "print '\\nRandom forest:'\n",
    "fit_print_scores(clf, features, labels)\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "print '\\nExtra trees:'\n",
    "fit_print_scores(clf, features, labels)\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "print '\\nAdaBoost:'\n",
    "fit_print_scores(clf, features, labels)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "print('\\nLogistic regression:')\n",
    "fit_print_scores(clf, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most promising classifiers are:\n",
    "AdaBoost, Naive Bayes, and ExtraTrees. Will tune parameters for AdaBoost and ExtraTrees. Naive Bayes does not have parameters to tune. So will test on the same data as the other two to have a direct comparison.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.96      0.94        50\n",
      "        1.0       0.60      0.43      0.50         7\n",
      "\n",
      "avg / total       0.88      0.89      0.89        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels =\\\n",
    "train_test_split(features, labels, test_size = 0.4, random_state=0)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_features, train_labels)\n",
    "y_true, y_pred = test_labels, clf.predict(test_features)\n",
    "print classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 414 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done 664 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1431 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'n_estimators': 25, 'learning_rate': 1, 'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 1}\n",
      "Detailed classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.98      0.93        50\n",
      "        1.0       0.50      0.14      0.22         7\n",
      "\n",
      "avg / total       0.84      0.88      0.85        57\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 377 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 538 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=-1)]: Done 788 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed:  3.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'n_estimators': 25, 'learning_rate': 10, 'base_estimator__max_depth': None, 'base_estimator__min_samples_leaf': 16}\n",
      "Detailed classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00        50\n",
      "        1.0       0.12      1.00      0.22         7\n",
      "\n",
      "avg / total       0.02      0.12      0.03        57\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:  3.6min finished\n",
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "### Tune classifiers to achieve better than .3 precision and recall \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_parameters = {'base_estimator__max_depth' : [None, 3, 6, 12, 24, 48],\n",
    "                    'base_estimator__min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "                    'n_estimators': [25, 50, 100, 250],\n",
    "                    'learning_rate': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state=1, class_weight='balanced')\n",
    "\n",
    "ABC = AdaBoostClassifier(base_estimator=DTC, random_state=2)\n",
    "\n",
    "clf_dict = {'ABC': {}}\n",
    "for score in scores:\n",
    "    print \"# Tuning hyper-parameters for %s\\n\" % score\n",
    "    clf = GridSearchCV(ABC, param_grid=tuned_parameters, cv=5, \n",
    "                       verbose=1, n_jobs=-1,\n",
    "                       scoring='%s' % score)\n",
    "    clf.fit(train_features, train_labels)\n",
    "\n",
    "    print 'Best parameters set found on development set:'\n",
    "    print clf.best_params_\n",
    "\n",
    "    print 'Detailed classification report:'\n",
    "    \n",
    "    y_true, y_pred = test_labels, clf.predict(test_features)\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3600 out of 3600 | elapsed: 12.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'max_features': 2, 'n_estimators': 50, 'max_depth': 3, 'min_samples_leaf': 2}\n",
      "Detailed classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.98      0.95        50\n",
      "        1.0       0.75      0.43      0.55         7\n",
      "\n",
      "avg / total       0.90      0.91      0.90        57\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=-1)]: Done 459 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1259 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1809 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2459 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3209 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3600 out of 3600 | elapsed: 11.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'max_features': 2, 'n_estimators': 25, 'max_depth': None, 'min_samples_leaf': 4}\n",
      "Detailed classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.86      0.89        50\n",
      "        1.0       0.30      0.43      0.35         7\n",
      "\n",
      "avg / total       0.84      0.81      0.82        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {'max_depth' : [None, 3, 6, 12, 24, 48],\n",
    "                    'min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "                    'n_estimators': [25, 50, 100, 250],\n",
    "                    'max_features': [1, 2, 4, 6, 8, 10]}\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "ETC = ExtraTreesClassifier(random_state=2, class_weight='balanced')\n",
    "\n",
    "clf_dict['ETC'] = {}\n",
    "for score in scores:\n",
    "    print \"# Tuning hyper-parameters for %s\\n\" % score\n",
    "    clf = GridSearchCV(ETC, param_grid=tuned_parameters, cv=5, \n",
    "                       verbose=1, n_jobs=-1,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(train_features, train_labels)\n",
    "\n",
    "    print 'Best parameters set found on development set:'\n",
    "    print clf.best_params_\n",
    "\n",
    "    print 'Detailed classification report:'\n",
    "    \n",
    "    y_true, y_pred = test_labels, clf.predict(test_features)\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/TRN/anaconda/envs/ml27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3600 out of 3600 | elapsed: 11.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'max_features': 2, 'n_estimators': 50, 'max_depth': 3, 'min_samples_leaf': 2}\n",
      "Detailed classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.98      0.95        50\n",
      "        1.0       0.75      0.43      0.55         7\n",
      "\n",
      "avg / total       0.90      0.91      0.90        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {'max_depth' : [None, 3, 6, 12, 24, 48],\n",
    "                    'min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "                    'n_estimators': [25, 50, 100, 250],\n",
    "                    'max_features': [1, 2, 4, 6, 8, 10]}\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "ETC = ExtraTreesClassifier(random_state=2, class_weight='balanced')\n",
    "\n",
    "clf_dict['ETC'] = {}\n",
    "for score in scores:\n",
    "    print \"# Tuning hyper-parameters for %s\\n\" % score\n",
    "    clf = GridSearchCV(ETC, param_grid=tuned_parameters, cv=5, \n",
    "                       verbose=1, n_jobs=-1,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(train_features, train_labels)\n",
    "\n",
    "    print 'Best parameters set found on development set:'\n",
    "    print clf.best_params_\n",
    "\n",
    "    print 'Detailed classification report:'\n",
    "    \n",
    "    y_true, y_pred = test_labels, clf.predict(test_features)\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight='balanced',\n",
       "           criterion='gini', max_depth=None, max_features=6,\n",
       "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=16, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random_state to None\n",
    "clf.set_params(random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Dump classifier, dataset, and features_list so anyone can check your results.\n",
    "\n",
    "from tools.tester import dump_classifier_and_data\n",
    "clf = clf_dict['ETC']['recall'].best_estimator_\n",
    "my_dataset = fin_data\n",
    "features_list = selected_feature_names\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Done loading\n",
      "Start testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ExtraTreesClassifier(bootstrap=False, class_weight='balanced',\n",
      "           criterion='gini', max_depth=None, max_features=6,\n",
      "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=16, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.68833\tPrecision: 0.26904\tRecall: 0.77900\tF1: 0.39995\tF2: 0.56486\n",
      "\tTotal predictions: 15000\tTrue positives: 1558\tFalse positives: 4233\tFalse negatives:  442\tTrue negatives: 8767\n",
      "\n",
      "Done testing\n"
     ]
    }
   ],
   "source": [
    "run tools/tester.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
