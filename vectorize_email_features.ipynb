{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-Idf feature extraction\n",
    "\n",
    "With the data organized into a dictionary extract text features based on term-frequency times inverse document-frequency (Tf-Idf) vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dictionary created in [email_features](email_features.ipynb) with email archive organized by email as `full_text_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "HOME_PATH = os.path.expanduser('~')\n",
    "DATA_PATH = os.path.join(HOME_PATH, 'Desktop', 'raw_data', 'ml')\n",
    "\n",
    "full_text_path = os.path.join(DATA_PATH, 'full_text_dict.pkl')\n",
    "with open(full_text_path, 'rb') as f:\n",
    "    full_text_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def email_list_and_labels(word_dict):\n",
    "    \"\"\"\n",
    "    Consolidates all the emails into a single string that can be used for \n",
    "    TfIdf vectorization\n",
    "    \n",
    "    Returns a list of dictos:\n",
    "    {email: email\n",
    "    poi: True/False\n",
    "    to_text: all words in emails to this email\n",
    "    from_text: all words in emails from this emails}\n",
    "    \"\"\"\n",
    "    dicto_list = []\n",
    "    \n",
    "    for key in word_dict:\n",
    "        \n",
    "        dicto = {'email': key, 'poi': word_dict[key]['poi']}\n",
    "        \n",
    "        to_compilation = []\n",
    "        from_compilation = []\n",
    "        \n",
    "        if 'to' in word_dict[key]:\n",
    "            for temp_d in word_dict[key]['to']:\n",
    "                to_compilation.append(temp_d['stemmed'])\n",
    "                \n",
    "        if 'from' in word_dict[key]:\n",
    "            for temp_d in word_dict[key]['from']:\n",
    "                from_compilation.append(temp_d['stemmed'])\n",
    "        \n",
    "        to_compilation = ''.join(to_compilation)\n",
    "        from_compilation = ''.join(from_compilation)\n",
    "        \n",
    "        dicto['to_text'] = to_compilation\n",
    "        dicto['from_text'] = from_compilation\n",
    "        \n",
    "        dicto_list.append(dicto)\n",
    "        \n",
    "        print '.',\n",
    "\n",
    "    return dicto_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "text_dicts = email_list_and_labels(full_text_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate emails into to, from, or all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_emails = [(dicto['poi'], \n",
    "                  dicto['to_text'], \n",
    "                  dicto['from_text'], \n",
    "                  dicto['to_text'] + ' ' + dicto['from_text'],\n",
    "                  dicto['email'])\n",
    "                 for dicto in text_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels, to_text, from_text, all_text, emails = zip(*labels_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 90, 90, 90)\n"
     ]
    }
   ],
   "source": [
    "print(len(to_text), len(from_text), len(all_text), len(emails))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the actual vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From array shape: (90, 42115), To array shape: (90, 62495), All array shape: (90, 74006)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "\n",
    "from_array = vectorizer.fit_transform(from_text)\n",
    "to_array = vectorizer.fit_transform(to_text)\n",
    "all_array = vectorizer.fit_transform(all_text)\n",
    "print('From array shape: {}, To array shape: {}, All array shape: {}' \n",
    "      .format(from_array.shape, to_array.shape, all_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_from_features, test_from_features, train_from_labels, test_from_labels =\\\n",
    "train_test_split(from_array, labels, test_size=0.4, random_state=30)\n",
    "\n",
    "train_to_features, test_to_features, train_to_labels, test_to_labels =\\\n",
    "train_test_split(to_array, labels, test_size=0.4, random_state=30)\n",
    "\n",
    "train_all_features, test_all_features, train_all_labels, test_all_labels =\\\n",
    "train_test_split(all_array, labels, test_size=0.4, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the word vectors using Naive Bayes. The testing compares vectors using words from all messages to and from an email with those just from an email. It also compares different selection methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2, mutual_info_classif\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def tester(percent, train_features, test_features, train_labels, test_labels):\n",
    "    scr_list = [f_classif, chi2] #, mutual_info_classif]\n",
    "    clf = GaussianNB()\n",
    "    for scr in scr_list:\n",
    "        print(scr)\n",
    "        selector = SelectPercentile(scr, percentile=percent)\n",
    "        try:\n",
    "            train_features_sel = selector.fit_transform(train_features, train_labels).toarray()\n",
    "            test_features_sel = selector.transform(test_features).toarray()\n",
    "        except AttributeError:\n",
    "            train_features_sel = selector.fit_transform(train_features, train_labels)\n",
    "            test_features_sel = selector.transform(test_features)\n",
    "        clf.fit(train_features_sel, train_labels)\n",
    "        pred = clf.predict(test_features_sel)\n",
    "        print(classification_report(test_labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% FROM:\n",
      "<function f_classif at 0x1122bc9b0>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.85      0.79      0.81        28\n",
      "       True       0.40      0.50      0.44         8\n",
      "\n",
      "avg / total       0.75      0.72      0.73        36\n",
      "\n",
      "<function chi2 at 0x1122bc6e0>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.81      0.89      0.85        28\n",
      "       True       0.40      0.25      0.31         8\n",
      "\n",
      "avg / total       0.72      0.75      0.73        36\n",
      "\n",
      "<function mutual_info_classif at 0x11251a500>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.81      0.79      0.80        28\n",
      "       True       0.33      0.38      0.35         8\n",
      "\n",
      "avg / total       0.71      0.69      0.70        36\n",
      "\n",
      "#########\n",
      "10% TO:\n",
      "<function f_classif at 0x1122bc9b0>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      0.21      0.35        28\n",
      "       True       0.27      1.00      0.42         8\n",
      "\n",
      "avg / total       0.84      0.39      0.37        36\n",
      "\n",
      "<function chi2 at 0x1122bc6e0>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.46      0.58        28\n",
      "       True       0.21      0.50      0.30         8\n",
      "\n",
      "avg / total       0.64      0.47      0.52        36\n",
      "\n",
      "<function mutual_info_classif at 0x11251a500>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.83      0.86      0.84        28\n",
      "       True       0.43      0.38      0.40         8\n",
      "\n",
      "avg / total       0.74      0.75      0.74        36\n",
      "\n",
      "#########\n",
      "10% ALL:\n",
      "<function f_classif at 0x1122bc9b0>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      0.07      0.13        28\n",
      "       True       0.24      1.00      0.38         8\n",
      "\n",
      "avg / total       0.83      0.28      0.19        36\n",
      "\n",
      "<function chi2 at 0x1122bc6e0>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.85      0.61      0.71        28\n",
      "       True       0.31      0.62      0.42         8\n",
      "\n",
      "avg / total       0.73      0.61      0.64        36\n",
      "\n",
      "<function mutual_info_classif at 0x11251a500>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.85      0.79      0.81        28\n",
      "       True       0.40      0.50      0.44         8\n",
      "\n",
      "avg / total       0.75      0.72      0.73        36\n",
      "\n",
      "#########\n",
      "5% FROM:\n",
      "<function f_classif at 0x1122bc9b0>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.86      0.43      0.57        28\n",
      "       True       0.27      0.75      0.40         8\n",
      "\n",
      "avg / total       0.73      0.50      0.53        36\n",
      "\n",
      "<function chi2 at 0x1122bc6e0>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.79      0.54      0.64        28\n",
      "       True       0.24      0.50      0.32         8\n",
      "\n",
      "avg / total       0.67      0.53      0.57        36\n",
      "\n",
      "<function mutual_info_classif at 0x11251a500>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.79      0.96      0.87        28\n",
      "       True       0.50      0.12      0.20         8\n",
      "\n",
      "avg / total       0.73      0.78      0.72        36\n",
      "\n",
      "#########\n",
      "5% TO:\n",
      "<function f_classif at 0x1122bc9b0>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.80      0.29      0.42        28\n",
      "       True       0.23      0.75      0.35         8\n",
      "\n",
      "avg / total       0.67      0.39      0.41        36\n",
      "\n",
      "<function chi2 at 0x1122bc6e0>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.25      0.38        28\n",
      "       True       0.22      0.75      0.34         8\n",
      "\n",
      "avg / total       0.65      0.36      0.37        36\n",
      "\n",
      "<function mutual_info_classif at 0x11251a500>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.75      0.76        28\n",
      "       True       0.22      0.25      0.24         8\n",
      "\n",
      "avg / total       0.65      0.64      0.65        36\n",
      "\n",
      "#########\n",
      "5% ALL:\n",
      "<function f_classif at 0x1122bc9b0>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.83      0.18      0.29        28\n",
      "       True       0.23      0.88      0.37         8\n",
      "\n",
      "avg / total       0.70      0.33      0.31        36\n",
      "\n",
      "<function chi2 at 0x1122bc6e0>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.25      0.39        28\n",
      "       True       0.25      0.88      0.39         8\n",
      "\n",
      "avg / total       0.74      0.39      0.39        36\n",
      "\n",
      "<function mutual_info_classif at 0x11251a500>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.82      0.82      0.82        28\n",
      "       True       0.38      0.38      0.38         8\n",
      "\n",
      "avg / total       0.72      0.72      0.72        36\n",
      "\n",
      "#########\n"
     ]
    }
   ],
   "source": [
    "print '10% FROM:'\n",
    "tester(10, train_from_features, test_from_features, train_from_labels, test_from_labels)\n",
    "print '#########'\n",
    "print '10% TO:'\n",
    "tester(10, train_to_features, test_to_features, train_to_labels, test_to_labels)\n",
    "print '#########'\n",
    "print '10% ALL:'\n",
    "tester(10, train_all_features, test_all_features, train_all_labels, test_all_labels)\n",
    "print '#########'\n",
    "print '5% FROM:'\n",
    "tester(5, train_from_features, test_from_features, train_from_labels, test_from_labels)\n",
    "print '#########'\n",
    "print '5% TO:'\n",
    "tester(5, train_to_features, test_to_features, train_to_labels, test_to_labels)\n",
    "print '#########'\n",
    "print '5% ALL:'\n",
    "tester(5, train_all_features, test_all_features, train_all_labels, test_all_labels)\n",
    "print '#########'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From words combined by selection using f_classif yields the f1 score for the True classification: 0.44. Will use this data for the full analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_email_text_path = os.path.join(DATA_PATH, 'label_email_text.pkl')\n",
    "\n",
    "with open(label_email_text_path, 'wb') as f:\n",
    "    pickle.dump(labels_emails, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
